{
    "base_model": "Qwen/Qwen3-0.6B",
    "finetuning": true,
    "use_dora": true,
    "n_epochs": 5,
    "lora_r": 32,
    "lora_alpha": 64,
    "lr": 0.0005,
    "batch_size": 16,
    "lora_projections": [
        "q_proj",
        "v_proj",
        "k_proj",
        "o_proj",
        "gate_proj",
        "down_proj",
        "up_proj"
    ],
    "lora_dropout": 0.05,
    "new_tokens_path": null,
    "new_tokens_init": "random",
    "new_tokens_train": true,
    "wandb_project": "Orange-LoRA-tutorial",
    "model_name": "Qwen3-0.6B_DoRA_qvkogdu_r32_alpha64_drop0.05_proj(qvkogdu)_bs16_lr0.0005_ep5__",
    "accuracy_mcq": 76.5,
    "se_mcq": 2.9981244136960026,
    "accuracy_mcq_con": 92.5,
    "se_mcq_con": 1.8624580532189172
}