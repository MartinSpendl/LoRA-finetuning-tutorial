{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c73770",
   "metadata": {},
   "source": [
    "# 5.1 - Evaluate finetuned models over each checkpoint (1 for epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5226a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "from evaluation_function import evaluate_model\n",
    "from utils import define_model_name\n",
    "from store_load_results import store_results, load_results\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cfdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINDATA_FILE = os.path.join(os.getcwd(), '..', 'data', 'train_test_dataset', 'orange_qa_train.jsonl')\n",
    "TESTDATA_MCQ_FILE = os.path.join(os.getcwd(), '..', 'data', 'train_test_dataset', 'orange_qa_MCQ_test.jsonl')\n",
    "TESTDATA_MCQ_CON_FILE = os.path.join(os.getcwd(), '..', 'data', 'train_test_dataset', 'orange_qa_MCQ-con_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c574b055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration: Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20__\n"
     ]
    }
   ],
   "source": [
    "LORA_PROJECTIONS = \"qvko\"\n",
    "PROJECTIONS = {\n",
    "    \"q\": \"q_proj\",\n",
    "    \"k\": \"k_proj\",\n",
    "    \"v\": \"v_proj\",\n",
    "    \"o\": \"o_proj\",\n",
    "    \"g\": \"gate_proj\",\n",
    "    \"d\": \"down_proj\",\n",
    "    \"u\": \"up_proj\"\n",
    "}\n",
    "projections = [PROJECTIONS[p] for p in list(LORA_PROJECTIONS)]\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"base_model\": \"Qwen/Qwen3-0.6B\",\n",
    "    \"finetuning\": True,\n",
    "    \"use_dora\": False,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lora_r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 16,\n",
    "    \"lora_projections\": projections,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"new_tokens_path\":  None,\n",
    "    \"new_tokens_init\": None,\n",
    "    \"new_tokens_train\": None,\n",
    "    \"wandb_project\": None,  # wandb project name\n",
    "}\n",
    "model_name, OUTPUT_DIR = define_model_name(MODEL_CONFIG)\n",
    "OUTPUT_DIR = OUTPUT_DIR.replace(\"notebooks/models\", \"notebooks/../models\")  # adjust for model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973a7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_both_datasets(model_config, output_dir, checkpoint_id:int=3640, epoch_id:int=20):\n",
    "    MODEL_CONFIG = model_config.copy()\n",
    "    OUTPUT_DIR = os.path.join(output_dir, f\"checkpoint-{checkpoint_id}\")\n",
    "    MODEL_CONFIG['n_epochs'] = epoch_id\n",
    "    MODEL_CONFIG['model_name'] = model_name.replace(\"ep20\", f\"ep20({epoch_id})\")\n",
    "\n",
    "    try:\n",
    "        results_dir = os.path.join(os.getcwd(), '..', 'results')\n",
    "        with open(os.path.join(results_dir, f'{MODEL_CONFIG[\"model_name\"]}_results.json'), 'r') as f:\n",
    "            return json.load(f)\n",
    "        print(\"Results already exist:\", results)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(\"No existing results found. Proceeding with evaluation.\", str(e))\n",
    "\n",
    "    # 11. Load model and tokenizer\n",
    "    if MODEL_CONFIG['finetuning']:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n",
    "        # Load base model first, then load PEFT adapter\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_CONFIG['base_model'], \n",
    "            device_map=\"auto\", \n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        base_model.resize_token_embeddings(len(tokenizer))\n",
    "        model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL_CONFIG['base_model'], device_map=\"auto\", torch_dtype=torch.float16)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG['base_model'], trust_remote_code=True)\n",
    "\n",
    "    # 12. Evaluate and store results\n",
    "    with open(TESTDATA_MCQ_FILE, \"r\") as f:\n",
    "        test_mcq_dataset = json.load(f)\n",
    "    accuracy_mcq, se_mcq = evaluate_model(model, tokenizer, test_mcq_dataset, batch_size=MODEL_CONFIG['batch_size'])\n",
    "\n",
    "    with open(TESTDATA_MCQ_CON_FILE, \"r\") as f:\n",
    "        test_mcq_con_dataset = json.load(f)\n",
    "    accuracy_mcq_con, se_mcq_con = evaluate_model(model, tokenizer, test_mcq_con_dataset, batch_size=MODEL_CONFIG['batch_size'])\n",
    "    results = {\n",
    "        \"accuracy_mcq\": accuracy_mcq,\n",
    "        \"se_mcq\": se_mcq,\n",
    "        \"accuracy_mcq_con\": accuracy_mcq_con,\n",
    "        \"se_mcq_con\": se_mcq_con,\n",
    "    }\n",
    "    print(\"Evaluation Results:\", results)\n",
    "    results_dir = os.path.join(os.getcwd(), '..', 'results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(results_dir, f'{MODEL_CONFIG[\"model_name\"]}_results.json'), 'w') as f:\n",
    "        json.dump(MODEL_CONFIG | results, f, indent=4)\n",
    "    print(\"Results stored successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35fff78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint 182 for epoch 1\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(1)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:15<00:00,  1.23s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:31<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(48.0), 'se_mcq': np.float64(3.5327043465311387), 'accuracy_mcq_con': np.float64(16.0), 'se_mcq_con': np.float64(2.592296279363144)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 364 for epoch 2\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(2)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:15<00:00,  1.23s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:38<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(62.0), 'se_mcq': np.float64(3.4322004603461025), 'accuracy_mcq_con': np.float64(10.5), 'se_mcq_con': np.float64(2.1676600286945367)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 546 for epoch 3\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(3)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:14<00:00,  1.12s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:30<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(55.5), 'se_mcq': np.float64(3.514078826662828), 'accuracy_mcq_con': np.float64(11.5), 'se_mcq_con': np.float64(2.255825791146116)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 728 for epoch 4\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(4)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:23<00:00,  1.83s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:53<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(57.5), 'se_mcq': np.float64(3.4955328635273903), 'accuracy_mcq_con': np.float64(13.0), 'se_mcq_con': np.float64(2.378024390118823)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 910 for epoch 5\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(5)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:18<00:00,  1.43s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:40<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(63.5), 'se_mcq': np.float64(3.40422531569225), 'accuracy_mcq_con': np.float64(15.5), 'se_mcq_con': np.float64(2.5590525590538387)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 1092 for epoch 6\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(6)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:35<00:00,  2.74s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [01:06<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(61.0), 'se_mcq': np.float64(3.448912872196107), 'accuracy_mcq_con': np.float64(16.0), 'se_mcq_con': np.float64(2.592296279363144)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 1274 for epoch 7\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(7)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:31<00:00,  2.38s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:53<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(55.5), 'se_mcq': np.float64(3.514078826662828), 'accuracy_mcq_con': np.float64(13.5), 'se_mcq_con': np.float64(2.4163505540380514)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 1456 for epoch 8\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(8)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:16<00:00,  1.28s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:46<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(53.0), 'se_mcq': np.float64(3.529164207004259), 'accuracy_mcq_con': np.float64(12.0), 'se_mcq_con': np.float64(2.2978250586152114)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 1638 for epoch 9\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(9)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:25<00:00,  2.00s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:43<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(50.0), 'se_mcq': np.float64(3.5355339059327373), 'accuracy_mcq_con': np.float64(20.0), 'se_mcq_con': np.float64(2.82842712474619)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 1820 for epoch 10\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(10)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:38<00:00,  2.95s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [01:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(44.5), 'se_mcq': np.float64(3.514078826662828), 'accuracy_mcq_con': np.float64(11.0), 'se_mcq_con': np.float64(2.2124646889837587)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2002 for epoch 11\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(11)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:34<00:00,  2.67s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:53<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(37.0), 'se_mcq': np.float64(3.413942003022312), 'accuracy_mcq_con': np.float64(14.5), 'se_mcq_con': np.float64(2.489728900904675)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2184 for epoch 12\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(12)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:38<00:00,  2.97s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [01:03<00:00,  4.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(38.0), 'se_mcq': np.float64(3.4322004603461025), 'accuracy_mcq_con': np.float64(10.5), 'se_mcq_con': np.float64(2.1676600286945367)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2366 for epoch 13\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(13)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:29<00:00,  2.24s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:55<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(46.0), 'se_mcq': np.float64(3.524202037341219), 'accuracy_mcq_con': np.float64(11.0), 'se_mcq_con': np.float64(2.2124646889837587)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2548 for epoch 14\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(14)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:28<00:00,  2.23s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:56<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(38.5), 'se_mcq': np.float64(3.440748465087211), 'accuracy_mcq_con': np.float64(12.0), 'se_mcq_con': np.float64(2.2978250586152114)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2730 for epoch 15\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(15)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:21<00:00,  1.69s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:56<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(39.0), 'se_mcq': np.float64(3.448912872196107), 'accuracy_mcq_con': np.float64(13.5), 'se_mcq_con': np.float64(2.4163505540380514)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 2912 for epoch 16\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(16)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:21<00:00,  1.65s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:54<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(38.5), 'se_mcq': np.float64(3.440748465087211), 'accuracy_mcq_con': np.float64(14.0), 'se_mcq_con': np.float64(2.453568829277059)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 3094 for epoch 17\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(17)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:27<00:00,  2.13s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:44<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(36.0), 'se_mcq': np.float64(3.394112549695428), 'accuracy_mcq_con': np.float64(12.5), 'se_mcq_con': np.float64(2.3385358667337135)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 3276 for epoch 18\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(18)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:19<00:00,  1.54s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:47<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(37.0), 'se_mcq': np.float64(3.413942003022312), 'accuracy_mcq_con': np.float64(15.5), 'se_mcq_con': np.float64(2.5590525590538387)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 3458 for epoch 19\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(19)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:22<00:00,  1.76s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:40<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(38.5), 'se_mcq': np.float64(3.440748465087211), 'accuracy_mcq_con': np.float64(15.0), 'se_mcq_con': np.float64(2.5248762345905194)}\n",
      "Results stored successfully.\n",
      "Evaluating checkpoint 3640 for epoch 20\n",
      "No existing results found. Proceeding with evaluation. [Errno 2] No such file or directory: '/root/dev/Tutorials/LoRA-finetuning-tutorial/notebooks/../results/Qwen3-0.6B_LoRA_qvko_r8_alpha16_drop0.05_proj(qvko)_bs16_lr0.0001_ep20(20)___results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model: 100%|██████████| 13/13 [00:23<00:00,  1.81s/it]\n",
      "Evaluating model: 100%|██████████| 13/13 [00:46<00:00,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'accuracy_mcq': np.float64(40.5), 'se_mcq': np.float64(3.4711309396218404), 'accuracy_mcq_con': np.float64(14.0), 'se_mcq_con': np.float64(2.453568829277059)}\n",
      "Results stored successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoints = {\n",
    "    i: 182*i for i in range(1, 21)\n",
    "}\n",
    "for epoch, checkpoint in checkpoints.items():\n",
    "    print(f\"Evaluating checkpoint {checkpoint} for epoch {epoch}\")\n",
    "    evaluate_model_on_both_datasets(MODEL_CONFIG, OUTPUT_DIR, checkpoint_id=checkpoint, epoch_id=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82091bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
