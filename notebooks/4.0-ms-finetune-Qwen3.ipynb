{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9eea854",
   "metadata": {},
   "source": [
    "# 4.0 - Finetune Qwen3 0.6B on Orange QA train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcef8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/Documents/FRI/Workshops/LoRA-tutorial/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MODEL_ID = \"Qwen/Qwen3-0.6B\"\n",
    "PEFT_SUFFIX = \"LoRA_qkvo\"\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), '..', 'models', f\"orange_qa_finetuned_{MODEL_ID.split('/')[-1]}_{PEFT_SUFFIX}\")\n",
    "DATA_FILE = os.path.join(os.getcwd(), '..', 'data', 'train_test_dataset', 'orange_qa_train.jsonl')\n",
    "\n",
    "# 1. Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token # Fix: Qwen has no default pad token\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=DATA_FILE, split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863ab3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "base_model.model.model.layers.0.self_attn.q_proj\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.0.self_attn.k_proj\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.0.self_attn.v_proj\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.0.self_attn.o_proj\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.0.mlp.gate_proj\n",
      "base_model.model.model.layers.0.mlp.up_proj\n",
      "base_model.model.model.layers.0.mlp.down_proj\n",
      "base_model.model.model.layers.1.self_attn.q_proj\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.1.self_attn.k_proj\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.1.self_attn.v_proj\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.1.self_attn.o_proj\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.1.mlp.gate_proj\n",
      "base_model.model.model.layers.1.mlp.up_proj\n",
      "base_model.model.model.layers.1.mlp.down_proj\n",
      "base_model.model.model.layers.2.self_attn.q_proj\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.2.self_attn.k_proj\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.2.self_attn.v_proj\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.2.self_attn.o_proj\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.2.mlp.gate_proj\n",
      "base_model.model.model.layers.2.mlp.up_proj\n",
      "base_model.model.model.layers.2.mlp.down_proj\n",
      "base_model.model.model.layers.3.self_attn.q_proj\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.3.self_attn.k_proj\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.3.self_attn.v_proj\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.3.self_attn.o_proj\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.3.mlp.gate_proj\n",
      "base_model.model.model.layers.3.mlp.up_proj\n",
      "base_model.model.model.layers.3.mlp.down_proj\n",
      "base_model.model.model.layers.4.self_attn.q_proj\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.4.self_attn.k_proj\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.4.self_attn.v_proj\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.4.self_attn.o_proj\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.4.mlp.gate_proj\n",
      "base_model.model.model.layers.4.mlp.up_proj\n",
      "base_model.model.model.layers.4.mlp.down_proj\n",
      "base_model.model.model.layers.5.self_attn.q_proj\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.5.self_attn.k_proj\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.5.self_attn.v_proj\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.5.self_attn.o_proj\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.5.mlp.gate_proj\n",
      "base_model.model.model.layers.5.mlp.up_proj\n",
      "base_model.model.model.layers.5.mlp.down_proj\n",
      "base_model.model.model.layers.6.self_attn.q_proj\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.6.self_attn.k_proj\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.6.self_attn.v_proj\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.6.self_attn.o_proj\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.6.mlp.gate_proj\n",
      "base_model.model.model.layers.6.mlp.up_proj\n",
      "base_model.model.model.layers.6.mlp.down_proj\n",
      "base_model.model.model.layers.7.self_attn.q_proj\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.7.self_attn.k_proj\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.7.self_attn.v_proj\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.7.self_attn.o_proj\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.7.mlp.gate_proj\n",
      "base_model.model.model.layers.7.mlp.up_proj\n",
      "base_model.model.model.layers.7.mlp.down_proj\n",
      "base_model.model.model.layers.8.self_attn.q_proj\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.8.self_attn.k_proj\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.8.self_attn.v_proj\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.8.self_attn.o_proj\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.8.mlp.gate_proj\n",
      "base_model.model.model.layers.8.mlp.up_proj\n",
      "base_model.model.model.layers.8.mlp.down_proj\n",
      "base_model.model.model.layers.9.self_attn.q_proj\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.9.self_attn.k_proj\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.9.self_attn.v_proj\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.9.self_attn.o_proj\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.9.mlp.gate_proj\n",
      "base_model.model.model.layers.9.mlp.up_proj\n",
      "base_model.model.model.layers.9.mlp.down_proj\n",
      "base_model.model.model.layers.10.self_attn.q_proj\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.10.self_attn.k_proj\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.10.self_attn.v_proj\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.10.self_attn.o_proj\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.10.mlp.gate_proj\n",
      "base_model.model.model.layers.10.mlp.up_proj\n",
      "base_model.model.model.layers.10.mlp.down_proj\n",
      "base_model.model.model.layers.11.self_attn.q_proj\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.11.self_attn.k_proj\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.11.self_attn.v_proj\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.11.self_attn.o_proj\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.11.mlp.gate_proj\n",
      "base_model.model.model.layers.11.mlp.up_proj\n",
      "base_model.model.model.layers.11.mlp.down_proj\n",
      "base_model.model.model.layers.12.self_attn.q_proj\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.12.self_attn.k_proj\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.12.self_attn.v_proj\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.12.self_attn.o_proj\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.12.mlp.gate_proj\n",
      "base_model.model.model.layers.12.mlp.up_proj\n",
      "base_model.model.model.layers.12.mlp.down_proj\n",
      "base_model.model.model.layers.13.self_attn.q_proj\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.13.self_attn.k_proj\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.13.self_attn.v_proj\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.13.self_attn.o_proj\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.13.mlp.gate_proj\n",
      "base_model.model.model.layers.13.mlp.up_proj\n",
      "base_model.model.model.layers.13.mlp.down_proj\n",
      "base_model.model.model.layers.14.self_attn.q_proj\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.14.self_attn.k_proj\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.14.self_attn.v_proj\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.14.self_attn.o_proj\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.14.mlp.gate_proj\n",
      "base_model.model.model.layers.14.mlp.up_proj\n",
      "base_model.model.model.layers.14.mlp.down_proj\n",
      "base_model.model.model.layers.15.self_attn.q_proj\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.15.self_attn.k_proj\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.15.self_attn.v_proj\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.15.self_attn.o_proj\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.15.mlp.gate_proj\n",
      "base_model.model.model.layers.15.mlp.up_proj\n",
      "base_model.model.model.layers.15.mlp.down_proj\n",
      "base_model.model.model.layers.16.self_attn.q_proj\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.16.self_attn.k_proj\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.16.self_attn.v_proj\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.16.self_attn.o_proj\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.16.mlp.gate_proj\n",
      "base_model.model.model.layers.16.mlp.up_proj\n",
      "base_model.model.model.layers.16.mlp.down_proj\n",
      "base_model.model.model.layers.17.self_attn.q_proj\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.17.self_attn.k_proj\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.17.self_attn.v_proj\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.17.self_attn.o_proj\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.17.mlp.gate_proj\n",
      "base_model.model.model.layers.17.mlp.up_proj\n",
      "base_model.model.model.layers.17.mlp.down_proj\n",
      "base_model.model.model.layers.18.self_attn.q_proj\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.18.self_attn.k_proj\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.18.self_attn.v_proj\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.18.self_attn.o_proj\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.18.mlp.gate_proj\n",
      "base_model.model.model.layers.18.mlp.up_proj\n",
      "base_model.model.model.layers.18.mlp.down_proj\n",
      "base_model.model.model.layers.19.self_attn.q_proj\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.19.self_attn.k_proj\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.19.self_attn.v_proj\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.19.self_attn.o_proj\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.19.mlp.gate_proj\n",
      "base_model.model.model.layers.19.mlp.up_proj\n",
      "base_model.model.model.layers.19.mlp.down_proj\n",
      "base_model.model.model.layers.20.self_attn.q_proj\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.20.self_attn.k_proj\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.20.self_attn.v_proj\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.20.self_attn.o_proj\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.20.mlp.gate_proj\n",
      "base_model.model.model.layers.20.mlp.up_proj\n",
      "base_model.model.model.layers.20.mlp.down_proj\n",
      "base_model.model.model.layers.21.self_attn.q_proj\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.21.self_attn.k_proj\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.21.self_attn.v_proj\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.21.self_attn.o_proj\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.21.mlp.gate_proj\n",
      "base_model.model.model.layers.21.mlp.up_proj\n",
      "base_model.model.model.layers.21.mlp.down_proj\n",
      "base_model.model.model.layers.22.self_attn.q_proj\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.22.self_attn.k_proj\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.22.self_attn.v_proj\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.22.self_attn.o_proj\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.22.mlp.gate_proj\n",
      "base_model.model.model.layers.22.mlp.up_proj\n",
      "base_model.model.model.layers.22.mlp.down_proj\n",
      "base_model.model.model.layers.23.self_attn.q_proj\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.23.self_attn.k_proj\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.23.self_attn.v_proj\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.23.self_attn.o_proj\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.23.mlp.gate_proj\n",
      "base_model.model.model.layers.23.mlp.up_proj\n",
      "base_model.model.model.layers.23.mlp.down_proj\n",
      "base_model.model.model.layers.24.self_attn.q_proj\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.24.self_attn.k_proj\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.24.self_attn.v_proj\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.24.self_attn.o_proj\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.24.mlp.gate_proj\n",
      "base_model.model.model.layers.24.mlp.up_proj\n",
      "base_model.model.model.layers.24.mlp.down_proj\n",
      "base_model.model.model.layers.25.self_attn.q_proj\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.25.self_attn.k_proj\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.25.self_attn.v_proj\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.25.self_attn.o_proj\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.25.mlp.gate_proj\n",
      "base_model.model.model.layers.25.mlp.up_proj\n",
      "base_model.model.model.layers.25.mlp.down_proj\n",
      "base_model.model.model.layers.26.self_attn.q_proj\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.26.self_attn.k_proj\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.26.self_attn.v_proj\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.26.self_attn.o_proj\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.26.mlp.gate_proj\n",
      "base_model.model.model.layers.26.mlp.up_proj\n",
      "base_model.model.model.layers.26.mlp.down_proj\n",
      "base_model.model.model.layers.27.self_attn.q_proj\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_dropout\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.27.self_attn.k_proj\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_dropout\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.27.self_attn.v_proj\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_dropout\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.27.self_attn.o_proj\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_dropout\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.model.layers.27.mlp.gate_proj\n",
      "base_model.model.model.layers.27.mlp.up_proj\n",
      "base_model.model.model.layers.27.mlp.down_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/Documents/FRI/Workshops/LoRA-tutorial/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.float16,\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=4,        # Rank (Higher = more parameters to train, smarter but slower)\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], #, \"gate_proj\", \"down_proj\", \"up_proj\"],\n",
    "    use_dora=False, # <--- This enables DoRA (Better learning than standard LoRA)\n",
    ")\n",
    "\n",
    "model_dora = get_peft_model(model, peft_config)\n",
    "\n",
    "for name, module in model_dora.named_modules():\n",
    "    if 'proj' in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b77e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/Documents/FRI/Workshops/LoRA-tutorial/.venv/lib/python3.12/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/Users/martin/Documents/FRI/Workshops/LoRA-tutorial/.venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n",
      "/Users/martin/Documents/FRI/Workshops/LoRA-tutorial/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='151' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [151/151 02:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.722400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.300100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.932800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.770400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.791700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.175800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.984300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.976800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.960200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.973200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.955800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /Users/martin/Documents/FRI/Workshops/LoRA-tutorial/notebooks/../models/orange_qa_finetuned_Qwen3-0.6B_LoRA_qkvo...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 6. Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=1,          # How many times to read the docs\n",
    "    per_device_train_batch_size=4, \n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,                   # Use mixed precision\n",
    "    logging_steps=2,\n",
    "    optim=\"adamw_torch\",   \n",
    "    save_strategy=\"epoch\",       # Save a checkpoint every epoch\n",
    ")\n",
    "\n",
    "# 7. Initialize Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# 8. Train & Save\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
